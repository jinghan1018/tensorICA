@article{Teschendorff2018,
abstract = {There is an increased need for integrative analyses of multi-omic data. We present and benchmark a novel tensorial independent component analysis (tICA) algorithm against current state-of-the-art methods. We find that tICA outperforms competing methods in identifying biological sources of data variation at a reduced computational cost. On epigenetic data, tICA can identify methylation quantitative trait loci at high sensitivity. In the cancer context, tICA identifies gene modules whose expression variation across tumours is driven by copy-number or DNA methylation changes, but whose deregulation relative to normal tissue is independent of such alterations, a result we validate by direct analysis of individual data types.},
author = {Teschendorff, Andrew E. and Jing, Han and Paul, Dirk S. and Virta, Joni and Nordhausen, Klaus},
doi = {10.1186/s13059-018-1455-8},
isbn = {1305901814558},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Cancer,Dimensional reduction,Epigenome-wide association study,Independent component analysis,MQTL,Multi-omic,Tensor},
pmid = {29884221},
title = {{Tensorial blind source separation for improved analysis of multi-omic data}},
year = {2018}
}
@article{Teschendorff2011,
abstract = {A common difficulty in large-scale microarray studies is the presence of confounding factors, which may significantly skew estimates of statistical significance, cause unreliable feature selection and high false negative rates. To deal with these difficulties, an algorithmic framework known as Surrogate Variable Analysis (SVA) was recently proposed.},
author = {Teschendorff, Andrew E. and Zhuang, Joanna and Widschwendter, Martin},
doi = {10.1093/bioinformatics/btr171},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {11},
pages = {1496--1505},
pmid = {21471010},
title = {{Independent surrogate variable analysis to deconvolve confounding factors in large-scale microarray profiling studies}},
volume = {27},
year = {2011}
}
@article{Plerou2002,
abstract = {We analyze cross correlations between price fluctuations of different stocks using methods of random matrix theory (RMT). Using two large databases, we calculate cross-correlation matrices C of returns constructed from (i) 30-min returns of 1000 US stocks for the 2-yr period 1994-1995, (ii) 30-min returns of 881 US stocks for the 2-yr period 1996-1997, and (iii) 1-day returns of 422 US stocks for the 35-yr period 1962-1996. We test the statistics of the eigenvalues lambda(i) of C against a "null hypothesis"--a random correlation matrix constructed from mutually uncorrelated time series. We find that a majority of the eigenvalues of C fall within the RMT bounds [lambda(-),lambda(+)] for the eigenvalues of random correlation matrices. We test the eigenvalues of C within the RMT bound for universal properties of random matrices and find good agreement with the results for the Gaussian orthogonal ensemble of random matrices-implying a large degree of randomness in the measured cross-correlation coefficients. Further, we find that the distribution of eigenvector components for the eigenvectors corresponding to the eigenvalues outside the RMT bound display systematic deviations from the RMT prediction. In addition, we find that these "deviating eigenvectors" are stable in time. We analyze the components of the deviating eigenvectors and find that the largest eigenvalue corresponds to an influence common to all stocks. Our analysis of the remaining deviating eigenvectors shows distinct groups, whose identities correspond to conventionally identified business sectors. Finally, we discuss applications to the construction of portfolios of stocks that have a stable ratio of risk to return.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0108023},
author = {Plerou, Vasiliki and Gopikrishnan, Parameswaran and Rosenow, Bernd and Amaral, Lu{\'{i}}s A.Nunes and Guhr, Thomas and Stanley, H. Eugene},
doi = {10.1103/PhysRevE.65.066126},
eprint = {0108023},
isbn = {1063-651X},
issn = {1063651X},
journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics},
number = {6},
pmid = {12188802},
primaryClass = {cond-mat},
title = {{Random matrix approach to cross correlations in financial data}},
volume = {65},
year = {2002}
}
@inproceedings{Virta2017,
abstract = {{\textcopyright} 2016 IEEE. There are two aspects in functional magnetic resonance imaging (fMRI) data that make them awkward to analyse with traditional multivariate methods - high order and high dimension. The first of these refers to the tensorial nature of observations as array-valued elements instead of vectors. Although this can be circumvented by vectorizing the array, doing so simultaneously loses all the structural information in the original observations. The second aspect refers to the high dimensionality along each dimension making the concept of dimension reduction a valuable tool in the processing of fMRI data. Different methods of tensor dimension reduction are currently gaining popularity in literature, and in this paper we apply two recently proposed methods of tensorial independent component analysis to simulated task-based fMRI data. Additionally, as a preprocessing step we introduce a novel extension of PCA for tensors. The simulations show that when extracting a sufficiently large number of principal components, the tensor methods find the task signals very reliably, something the standard temporal independent component analysis (tICA) fails in.},
author = {Virta, Joni and Taskinen, Sara and Nordhausen, Klaus},
booktitle = {2016 IEEE Signal Processing in Medicine and Biology Symposium, SPMB 2016 - Proceedings},
doi = {10.1109/SPMB.2016.7846858},
isbn = {9781509067138},
title = {{Applying fully tensorial ICA to fMRI data}},
year = {2017}
}
@article{Virta2017a,
abstract = {In preprocessing tensor-valued data, e.g., images and videos, a common procedure is to vectorize the observations and subject the resulting vectors to one of the many methods used for independent component analysis (ICA). However, the tensor structure of the original data is lost in the vectorization and, as a more suitable alternative, we propose the matrix- and tensor fourth order blind identification (MFOBI and TFOBI). In these tensorial extensions of the classic fourth order blind identification (FOBI) we assume a Kronecker structure for the mixing and perform FOBI simultaneously on each direction of the observed tensors. We discuss the theory and assumptions behind MFOBI and TFOBI and provide two different algorithms and related estimates of the unmixing matrices along with their asymptotic properties. Finally, simulations are used to compare the method's performance with that of classical FOBI for vectorized data and we end with a real data clustering example.},
archivePrefix = {arXiv},
arxivId = {1602.00879},
author = {Virta, Joni and Li, Bing and Nordhausen, Klaus and Oja, Hannu},
doi = {10.1016/j.jmva.2017.09.008},
eprint = {1602.00879},
issn = {10957243},
journal = {Journal of Multivariate Analysis},
keywords = {FOBI,Kronecker structure,Matrix-valued data,Multilinear algebra},
pages = {172--192},
title = {{Independent component analysis for tensor-valued data}},
volume = {162},
year = {2017}
}
@article{JingH.Teschendorff2018,
author = {{Jing, H., Teschendorff}, E.A.},
number = {doi:10.5281/zenodo.1208040.},
pages = {https://doi.org/10.5281/zenodo.1208040},
title = {{R-scripts for implementing tensor decomposition methods}},
year = {2018}
}
